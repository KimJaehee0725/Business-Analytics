{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data \n",
    "데이터는 STL 10 데이터셋을 이용했다. 해당 데이터셋은 본래 소수의 Labeled 데이터와 다수의 Unlabled 데이터가 존재할 경우의 이미지 모델 평가를 위해 제안된 방법론이다. 본 튜토리얼에선 엄밀하게 Unlabeled Data도 Uniform Distribution을 만족시키고, Labeled Data의 수를 제한하고자, 기존의 Labeled Data에서 Labeled 및 Unlabeled Data를 분리했다. 또한, 기존의 다양한 Semi-Supervised Learning 연구방법론과 동일하게, Test 셋은 그대로 활용하여, 모델의 성능 평가 시 대수의 법칙을 따르도록 했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filename_base = \"/project/codes/02_KU_lectures/business_analytics/Business-Analytics/FlexMatch/dataset/stl10_binary/\"\n",
    "file_list = [filename_base + filename for filename in [\"train_X.bin\", \"train_y.bin\", \"test_X.bin\", \"test_y.bin\"]]\n",
    "files = [open(filename, \"rb\") for filename in file_list]\n",
    "\n",
    "train_X = np.fromfile(files[0], dtype=np.uint8).reshape(-1, 3, 96, 96).transpose(0, 2, 3, 1)\n",
    "train_y = np.fromfile(files[1], dtype=np.uint8)\n",
    "test_X = np.fromfile(files[2], dtype=np.uint8).reshape(-1, 3, 96, 96).transpose(0, 2, 3, 1)\n",
    "test_y = np.fromfile(files[3], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/project/codes/02_KU_lectures/business_analytics/Business-Analytics/FlexMatch/dataset/stl10_binary/fold_indices.txt\") as f :\n",
    "    fold_indices = f.readlines()\n",
    "fold_indices = [line.split() for line in fold_indices]\n",
    "with open(\"/project/codes/02_KU_lectures/business_analytics/Business-Analytics/FlexMatch/dataset/stl10_binary/class_names.txt\") as f :\n",
    "    class_names = f.readlines()\n",
    "class_names = [line.split() for line in class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_idx = [int(i) for i in fold_indices[0]]\n",
    "lab_class = [int(i) for i in train_y[lab_idx]]\n",
    "lab_X = train_X[lab_idx]\n",
    "ulb_idx = [int(i) for fold in fold_indices[1:] for i in fold]\n",
    "ulb_class = [int(i) for i in train_y[ulb_idx]]\n",
    "ulb_X = train_X[ulb_idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabeled Data 역시 Class가 Uniform Distribution이 되도록 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X.shape :  (8000, 96, 96, 3)\n",
      "test_y.shape :  (8000,)\n",
      "lab_idx.shape :  1000\n",
      "lab_class.shape :  1000\n",
      "lab_X.shape :  (1000, 96, 96, 3)\n",
      "ulb_idx.shape :  9000\n",
      "ulb_class.shape :  9000\n",
      "ulb_X.shape :  (9000, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_X.shape : \", test_X.shape)\n",
    "print(\"test_y.shape : \", test_y.shape)\n",
    "print(\"lab_idx.shape : \", len(lab_idx))\n",
    "print(\"lab_class.shape : \", len(lab_class))\n",
    "print(\"lab_X.shape : \", lab_X.shape)\n",
    "print(\"ulb_idx.shape : \", len(ulb_idx))\n",
    "print(\"ulb_class.shape : \", len(ulb_class))\n",
    "print(\"ulb_X.shape : \", ulb_X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이후 실험은 해당 파일을 이용하여 진행 예정\n",
    "- Labeled Data : 1000개(100개*10 class)\n",
    "- Unlabeled Data : 4000개(400개*10 class)\n",
    "- Test Data : 8000개(원본 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "save_dir = '/project/codes/02_KU_lectures/business_analytics/Business-Analytics/FlexMatch/dataset/SSL_data'\n",
    "\n",
    "with open(os.path.join(save_dir, 'train_y.pkl'), 'wb') as f:\n",
    "    pickle.dump(np.array(lab_class), f)\n",
    "with open(os.path.join(save_dir, 'unlabeled_y.pkl'), 'wb') as f:\n",
    "    pickle.dump(np.array(ulb_class), f)\n",
    "with open(os.path.join(save_dir, 'test_y.pkl'), 'wb') as f:\n",
    "    pickle.dump(np.array(test_y), f)\n",
    "with open(os.path.join(save_dir, 'train_X.pkl'), 'wb') as f:\n",
    "    pickle.dump(lab_X, f)\n",
    "with open(os.path.join(save_dir, 'unlabeled_X.pkl'), 'wb') as f:\n",
    "    pickle.dump(ulb_X, f)\n",
    "with open(os.path.join(save_dir, 'test_X.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_X, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
